"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.register = exports.getSemanticTokenLegend = void 0;
const shared = require("@volar/shared");
function getSemanticTokenLegend() {
    if (tokenTypes.length !== 12 /* TokenType._ */) {
        console.warn('TokenType has added new entries.');
    }
    if (tokenModifiers.length !== 6 /* TokenModifier._ */) {
        console.warn('TokenModifier has added new entries.');
    }
    return { tokenTypes, tokenModifiers };
}
exports.getSemanticTokenLegend = getSemanticTokenLegend;
function register(languageService, getTextDocument, ts) {
    return (uri, range, cancle) => {
        const document = getTextDocument(uri);
        if (!document)
            return;
        const file = shared.uriToFsPath(uri);
        const start = range ? document.offsetAt(range.start) : 0;
        const length = range ? (document.offsetAt(range.end) - start) : document.getText().length;
        if (cancle === null || cancle === void 0 ? void 0 : cancle.isCancellationRequested)
            return;
        let response2;
        try {
            response2 = languageService.getEncodedSyntacticClassifications(file, { start, length });
        }
        catch (_a) { }
        if (!response2)
            return;
        if (cancle === null || cancle === void 0 ? void 0 : cancle.isCancellationRequested)
            return;
        let response1;
        try {
            response1 = languageService.getEncodedSemanticClassifications(file, { start, length }, ts.SemanticClassificationFormat.TwentyTwenty);
        }
        catch (_b) { }
        if (!response1)
            return;
        const tokenSpan = [...response1.spans, ...response2.spans];
        const tokens = [];
        let i = 0;
        while (i < tokenSpan.length) {
            const offset = tokenSpan[i++];
            const length = tokenSpan[i++];
            const tsClassification = tokenSpan[i++];
            let tokenModifiers = 0;
            let tokenType = getTokenTypeFromClassification(tsClassification);
            if (tokenType !== undefined) {
                // it's a classification as returned by the typescript-vscode-sh-plugin
                tokenModifiers = getTokenModifierFromClassification(tsClassification);
            }
            else {
                // typescript-vscode-sh-plugin is not present
                tokenType = tokenTypeMap[tsClassification];
                if (tokenType === undefined) {
                    continue;
                }
            }
            // we can use the document's range conversion methods because the result is at the same version as the document
            const startPos = document.positionAt(offset);
            const endPos = document.positionAt(offset + length);
            for (let line = startPos.line; line <= endPos.line; line++) {
                const startCharacter = (line === startPos.line ? startPos.character : 0);
                const endCharacter = (line === endPos.line ? endPos.character : docLineLength(document, line));
                tokens.push([line, startCharacter, endCharacter - startCharacter, tokenType, tokenModifiers]);
            }
        }
        return tokens;
    };
}
exports.register = register;
function docLineLength(document, line) {
    const currentLineOffset = document.offsetAt({ line, character: 0 });
    const nextLineOffset = document.offsetAt({ line: line + 1, character: 0 });
    return nextLineOffset - currentLineOffset;
}
function getTokenTypeFromClassification(tsClassification) {
    if (tsClassification > 255 /* TokenEncodingConsts.modifierMask */) {
        return (tsClassification >> 8 /* TokenEncodingConsts.typeOffset */) - 1;
    }
    return undefined;
}
function getTokenModifierFromClassification(tsClassification) {
    return tsClassification & 255 /* TokenEncodingConsts.modifierMask */;
}
const tokenTypes = [];
tokenTypes[0 /* TokenType.class */] = 'class';
tokenTypes[1 /* TokenType.enum */] = 'enum';
tokenTypes[2 /* TokenType.interface */] = 'interface';
tokenTypes[3 /* TokenType.namespace */] = 'namespace';
tokenTypes[4 /* TokenType.typeParameter */] = 'typeParameter';
tokenTypes[5 /* TokenType.type */] = 'type';
tokenTypes[6 /* TokenType.parameter */] = 'parameter';
tokenTypes[7 /* TokenType.variable */] = 'variable';
tokenTypes[8 /* TokenType.enumMember */] = 'enumMember';
tokenTypes[9 /* TokenType.property */] = 'property';
tokenTypes[10 /* TokenType.function */] = 'function';
tokenTypes[11 /* TokenType.method */] = 'method';
const tokenModifiers = [];
tokenModifiers[2 /* TokenModifier.async */] = 'async';
tokenModifiers[0 /* TokenModifier.declaration */] = 'declaration';
tokenModifiers[3 /* TokenModifier.readonly */] = 'readonly';
tokenModifiers[1 /* TokenModifier.static */] = 'static';
tokenModifiers[5 /* TokenModifier.local */] = 'local';
tokenModifiers[4 /* TokenModifier.defaultLibrary */] = 'defaultLibrary';
// mapping for the original ExperimentalProtocol.ClassificationType from TypeScript (only used when plugin is not available)
const tokenTypeMap = [];
tokenTypeMap[11 /* ExperimentalProtocol.ClassificationType.className */] = 0 /* TokenType.class */;
tokenTypeMap[12 /* ExperimentalProtocol.ClassificationType.enumName */] = 1 /* TokenType.enum */;
tokenTypeMap[13 /* ExperimentalProtocol.ClassificationType.interfaceName */] = 2 /* TokenType.interface */;
tokenTypeMap[14 /* ExperimentalProtocol.ClassificationType.moduleName */] = 3 /* TokenType.namespace */;
tokenTypeMap[15 /* ExperimentalProtocol.ClassificationType.typeParameterName */] = 4 /* TokenType.typeParameter */;
tokenTypeMap[16 /* ExperimentalProtocol.ClassificationType.typeAliasName */] = 5 /* TokenType.type */;
tokenTypeMap[17 /* ExperimentalProtocol.ClassificationType.parameterName */] = 6 /* TokenType.parameter */;
//# sourceMappingURL=semanticTokens.js.map